{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will further process the Kaldi decoding lattice and score the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the lattice file (generated in 09_decode_back_HMM-GMM_and_WFST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latFile = os.path.join(dataDir, \"exp\", \"decode_test\", \"test.lat\")\n",
    "\n",
    "lat = exkaldi.decode.wfst.load_lat(latFile)\n",
    "\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be simple and straightforward, we get the 1-best result from lattice. Word-id table and HMM model are necessary.\n",
    "\n",
    "Word-id table can be words.txt file (If decoded in word level) or phones.txt file (If decoded in phone level) or Exkaldi ListTable object. \n",
    "Ideally, LexiconBank object is also avaliable because you can get both \"words\" and \"phones\" from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = os.path.join(dataDir, \"exp\", \"words.txt\")\n",
    "\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_1best(wordSymbolTable=wordsFile, hmm=hmmFile, lmwt=1, acwt=0.5)\n",
    "\n",
    "result.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___result___ is a exkaldi __Transcription__ object (a subclass of Python dict).\n",
    "\n",
    "The decoding result is int-ID format. If you want it by text-format, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textResult = exkaldi.hmm.transcription_from_int(result, wordsFile)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for convenience, we restorage lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del textResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the __transcription_from_int__ function, we can transform transcription by using the __Transcription__'s own method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = lexicons(\"words\")\n",
    "oovID = word2id[lexicons(\"oov\")]\n",
    "id2word = word2id.reverse()\n",
    "\n",
    "textResult = result.convert(id2word, oovID)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can score the decoding result. Typically, you can compute the WER(word err rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refFile = os.path.join(dataDir, \"test\", \"text\")\n",
    "\n",
    "score = exkaldi.decode.score.wer(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or some times, compute the edit distance score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = exkaldi.decode.score.edit_distance(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the accuracy of words levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - score.editDistance/score.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested this and only get the WER 168.74, and the accuracy rate of words is 16.67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support further process the lattice, for example, to add penalty or to scale it.\n",
    "\n",
    "Here is a example to config different language model weight(LMWT) and penalty. (In Instead of text-format result, we use int-format reference file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refInt = exkaldi.hmm.transcription_to_int(refFile, lexicons(\"words\"), unkSymbol=lexicons(\"oov\"))\n",
    "refIntFile = os.path.join(dataDir, \"exp\", \"decode_test\", \"text.int\")\n",
    "refInt.save(refIntFile)\n",
    "\n",
    "refInt.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for penalty in [0., 0.5, 1.0]:\n",
    "    for LMWT in range(10, 15):\n",
    "        \n",
    "        newLat = lat.add_penalty(penalty)\n",
    "        result = newLat.get_1best(lexicons(\"words\"), hmmFile, lmwt=LMWT, acwt=0.5)\n",
    "\n",
    "        score = exkaldi.decode.score.wer(ref=refInt, hyp=result, mode=\"present\")\n",
    "        \n",
    "        print(f\"Penalty {penalty}, LMWT {LMWT}: WER {score.WER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lattice, you can get the phone-level result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneResult = lat.get_1best(lexicons(\"phones\"), hmmFile, lmwt=1, acwt=0.5, phoneLevel=True)\n",
    "\n",
    "phoneResult = exkaldi.hmm.transcription_from_int(phoneResult, lexicons(\"phones\"))\n",
    "\n",
    "phoneResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lattice, N-Best results can also be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                )\n",
    "\n",
    "for re in result:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___phoneResult___ is a list of N-bests __Transcription__ objects. If ___requireCost___ is True, return the LM score and AM score sumultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=True,\n",
    "                )\n",
    "\n",
    "for re in result[0]:\n",
    "    print(re.name, type(re))\n",
    "    \n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))\n",
    "\n",
    "for re in result[2]:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And importantly, Alignment can be returned to support discriminative training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        wordSymbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                        requireAli=True,\n",
    "                )\n",
    "\n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
