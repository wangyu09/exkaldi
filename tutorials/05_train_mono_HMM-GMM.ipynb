{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will train a monophone HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, prepare lexicons. Restorage the LexiconBank from file (Generated in step 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = exkaldi.decode.graph.load_lex(os.path.join(dataDir, \"exp\", \"lexicons.lex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to  the HMM-GMM toponology file and acoustic feature data to initialize a monophone HMM-GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "\n",
    "exkaldi.hmm.make_toponology(lexicons, outFile=topoFile, numNonsilStates=3, numSilStates=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In early step (2_feature_processing), we have made the mfcc feature, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"train_mfcc_cmvn.ark\")\n",
    "\n",
    "feat = exkaldi.load_feat(featFile, name=\"mfcc\")\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add 2-order deltas to this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat.add_delta(order=2)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate a HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = exkaldi.hmm.MonophoneHMM(lexicons=lexicons, name=\"mono\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model___ is an exkaldi __MonophoneHMM__ object. Exkaldi have two types of HMM-GMM model.\n",
    "\n",
    "__MonophoneHMM__: the monphone HMM-GMM model.  \n",
    "__TriphoneHMM__: the context HMM-GMM model.  \n",
    "\n",
    "Now, this __model__ is void and unavaliable. We must initialize it's archtecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialize(feat=feat, topoFile=topoFile)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are about to train this model. We provide a high-level API, __model.train(...)__ to train this model in a nutshell, but we still introduce the basic training loop step by step here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HMM-GMM in detail\n",
    "\n",
    "#### 1. Prepare the int-ID format transcription.\n",
    "\n",
    "We actually use the transcription with int-ID format, so we convert text format to int-ID format firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "oov = lexicons(\"oov\")\n",
    "\n",
    "trans = exkaldi.hmm.transcription_to_int(transFile, lexicons, oov)\n",
    "\n",
    "type(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___trans___ is an exkaldi __Transcription__ object, which is designed to hold the transcription. We save the int-format transcription for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans.save(intTransFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at this transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compile the train graph.\n",
    "\n",
    "Compile the train graph. Here, L.fst file is necessary. In early step (3_prepare_lexicons), we have generated one, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though decision tree is actually useless when traing monophone HMM-GMM, Kaldi still need it. \n",
    "\n",
    "When the monophone HMM is initialized, a temporary tree is generated automatically. Use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.tree\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___tree___ is an exkaldi __DecisionTree__ object. In next step, we will introduce how to build a normal decision tree. But now, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_mono\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, pathIsFile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model.compile_train_graph(tree=tree, transcription=trans, LFile=Lfile, outFile=trainGraphFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the HMM-GMM model, a basic loop is:  \n",
    "\n",
    "    align feature >> accumulate statistics >> update gassian functions\n",
    "\n",
    "Then we introduce one training loop in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Align acoustic feature averagely in order to start the first train step.\n",
    "\n",
    "Kaldi align feature equally in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali = model.align_equally(feat, trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ali___ is an exkaldi __BytesAlignmentTrans__ object. It holds the alignment in transition-ID level. \n",
    "\n",
    "You can covert it to __NumPy__ format to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali.subset(nHead=1).to_numpy().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use alignment to accumulate the statistics in order to update the parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model.accumulate_stats(feat=feat, alignment=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use these statistics to update model parameters.\n",
    "\n",
    "This step can increase the numbers of gaussians. We try to use 10 more gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetGaussians = model.info.gaussians + 10\n",
    "\n",
    "model.update(statsFile, numgauss=targetGaussians)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next training step, use Viterbi aligning to instead of average aligning.\n",
    "\n",
    "#### 6. Align acoustic feature with Vertibi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali = model.align(feat=feat, trainGraphFile=trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali.subset(nHead=1).to_numpy().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic training loop is just like this. Actually, we have a high-level API to train the model.\n",
    "\n",
    "### Train HMM-GMM with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)\n",
    "del ali\n",
    "del trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to train 10 iterations.\n",
    "\n",
    "Note that the text format transcription is expected when you use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finalAli = model.train(feat, transFile, Lfile, tempDir=outDir, numIters=10, maxIterInc=8, totgauss=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An __ArkIndextable__ of final alignment object will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment are saved in files automatically. You can save them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFile = os.path.join(outDir, \"mono.mdl\")\n",
    "#model.save(modelFile)\n",
    "#treeFile = os.path.join(outDir, \"tree\")\n",
    "#tree.save(treeFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
