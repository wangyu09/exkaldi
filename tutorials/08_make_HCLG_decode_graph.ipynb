{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will make a HCLG decode graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare lexicons (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the traing of HMM and decision tree, we also have high-level API to make HCLG graph. But firstly we introduce how to build HCLG graph with exkaldi toolkit in detail.\n",
    "\n",
    "### Make HCLG in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\", \"graph\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, pathIsFile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compose __L.fst__ and __G.fst__ to __LG.fst__. \n",
    "\n",
    "__L.fst__ file has been generated before (in 3_prepare_lexicons), use it directly.  \n",
    "__G.fst__ file has been generated before (in 04_train_and_query_language_model), use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L_disambig.fst\")\n",
    "Gfile = os.path.join(dataDir, \"exp\", \"G.fst\")\n",
    "LGfile = os.path.join(outDir, \"LG.fst\")\n",
    "\n",
    "exkaldi.decode.graph.compose_LG(Lfile, Gfile, outFile=LGfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compose __LG__ and context information to __CLG.fst__. \n",
    "\n",
    "__tree__ will be used here. and __ilabel__ info will also be generated in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"tree\")\n",
    "CLGfile = os.path.join(outDir, \"CLG.fst\")\n",
    "\n",
    "_, ilabelFile = exkaldi.decode.graph.compose_CLG(lexicons, treeFile, LGfile, outFile=CLGfile)\n",
    "\n",
    "ilabelFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, compose all infos to final __HCLG.fst__ graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")\n",
    "HCLGFile = os.path.join(outDir, \"HCLG.fst\")\n",
    "\n",
    "exkaldi.decode.graph.compose_HCLG(hmmFile, treeFile, CLGfile, ilabelFile, outFile=HCLGFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make HCLG with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(LGfile)\n",
    "os.remove(CLGfile)\n",
    "os.remove(ilabelFile)\n",
    "os.remove(HCLGFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exkaldi.decode.graph.make_graph(lexicons, hmmFile, treeFile, tempDir=outDir, useLfile=Lfile, useGfile=Gfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified \"useLfile\" and \"useGfile\" to use the L and G fst file generated before. If you don't want this, specify \"useLfile\" and \"useGfile\" None, and other parameters, such as \"useDisambigLexicons\" and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
